## üîß Configuration du projet Airflow avec SSH et MinIO

### üñ•Ô∏è Architecture

- `server-airflow` : h√©berge Apache Airflow
- `server-file` : contient les fichiers √† r√©cup√©rer via SSH
- `server-minio` : stockage objet MinIO

---

### 1Ô∏è‚É£ G√©n√©rer une cl√© SSH sur `server-airflow`

Sur `server-airflow` :

```bash
ssh-keygen -t rsa -b 4096 -f ~/.ssh/id_rsa -N ""
```

> Cela cr√©e :

- Cl√© priv√©e : `/home/ubuntu/.ssh/id_rsa`
- Cl√© publique : `/home/ubuntu/.ssh/id_rsa.pub`

---

#### Copier la cl√© publique vers `server-file`

---

### 2Ô∏è‚É£ Cr√©er une connexion SSH dans Airflow

Dans l'interface Airflow (`Admin > Connections`) :

- **Connection Id** : `ssh_connection`
- **Connection Type** : `SSH`
- **Host** : `<IP-server-file>`
- **Username** : `ubuntu`
- **Password** : *(laisser vide)*
- **Port** : `22`
- **Extra** :

```json
{
  "key_file": "/home/ubuntu/.ssh/id_rsa"
}
```

---

### 3Ô∏è‚É£ Cr√©er une connexion MinIO dans Airflow

Dans `Admin > Connections` :

- **Connection Id** : `minio_connect`
- **Connection Type** : `Amazon Web Services`
- **AWS Access Key ID** : `minio-key`
- **AWS Secret Access Key** : `minio-secret`
- **Extra** :

```json
{
  "endpoint_url": "http://<IP-server-minio>:9000"
}
```

---

### 4Ô∏è‚É£  Cr√©er le DAG `final.py`

Ajoutez votre DAG dans le dossier `dags/` de votre instance Airflow :

```bash
touch ~/airflow/dags/final.py
```

R√©digez votre logique de DAG √† l‚Äôint√©rieur (connexion SSH + transfert + upload vers MinIO).
